<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Digital Audio Encoding Demo</title>
    <style>
        canvas { border: 1px solid black; width: 100%; height: 200px; }
        #record { background-color: red; color: white; }
    </style>
</head>
<body>
    <h1>Digital Audio Encoding Demo</h1>
    <canvas id="waveform"></canvas>
    <canvas id="digitalWaveform"></canvas>
    <br>
    <label>Sampling Rate: <input type="range" id="sampleRate" min="8000" max="44100" step="1000" value="44100"></label>
    <br>
    <label>Bit Depth: <input type="range" id="bitDepth" min="2" max="16" step="1" value="16"></label>
    <br>
    <p id="fileSize">File Size: 0 KB</p>
    <button id="record">Record</button>
    <button id="play">Play</button>
    <p>Binary Representation of Samples:</p>
    <pre id="binaryOutput"></pre>
    <script>
        const canvas = document.getElementById("waveform");
        const digitalCanvas = document.getElementById("digitalWaveform");
        const ctx = canvas.getContext("2d");
        const digitalCtx = digitalCanvas.getContext("2d");
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const sampleRateSlider = document.getElementById("sampleRate");
        const bitDepthSlider = document.getElementById("bitDepth");
        const recordButton = document.getElementById("record");
        const playButton = document.getElementById("play");
        const fileSizeDisplay = document.getElementById("fileSize");
        const binaryOutput = document.getElementById("binaryOutput");
        let audioBuffer;
        let recorder;
        let audioChunks = [];
        let mediaStream;
        let animationFrameId;
        const MAX_RECORD_TIME = 5000; // 5 seconds

        navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
            mediaStream = stream;
            recorder = new MediaRecorder(stream);
            recorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            recorder.onstart = () => {
                recordButton.style.backgroundColor = "green";
                recordButton.textContent = "Recording...";
                audioChunks = [];
            };
            recorder.onstop = async () => {
                recordButton.style.backgroundColor = "red";
                recordButton.textContent = "Record";
                cancelAnimationFrame(animationFrameId);
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                
                const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
                const arrayBuffer = await audioBlob.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                drawWaveform(audioBuffer, ctx);
                updateFileSize(audioBuffer);
            };
        }).catch(error => {
            console.error("Error accessing microphone:", error);
            alert("Microphone access is required for recording.");
        });

        recordButton.onclick = () => {
            if (recorder && recorder.state === "inactive") {
                recorder.start();
                setTimeout(() => {
                    if (recorder.state === "recording") {
                        recorder.stop();
                    }
                }, MAX_RECORD_TIME);
            }
        };

        playButton.onclick = () => {
            if (!audioBuffer) return;
            const source = audioContext.createBufferSource();
            source.buffer = audioBuffer;
            source.connect(audioContext.destination);
            source.start();
            drawWaveform(audioBuffer, digitalCtx);
            displayBinarySamples(audioBuffer);
        };

        function drawWaveform(buffer, context) {
            context.clearRect(0, 0, canvas.width, canvas.height);
            const data = buffer.getChannelData(0);
            context.beginPath();
            for (let i = 0; i < data.length; i += Math.floor(data.length / canvas.width)) {
                const x = (i / data.length) * canvas.width;
                const y = (1 - (data[i] + 1) / 2) * canvas.height;
                if (i === 0) context.moveTo(x, y);
                else context.lineTo(x, y);
            }
            context.stroke();
        }

        function displayBinarySamples(buffer) {
            const data = buffer.getChannelData(0);
            const bitDepth = bitDepthSlider.value;
            let binaryData = data.slice(0, 10).map(sample => {
                let quantized = quantizeSample(sample, bitDepth);
                return quantized.toFixed(3) + " -> " + (Math.round(quantized * ((1 << bitDepth) - 1))).toString(2).padStart(bitDepth, '0');
            }).join('\n');
            binaryOutput.textContent = binaryData;
        }

        function quantizeSample(sample, bitDepth) {
            const levels = Math.pow(2, bitDepth) - 1;
            return Math.round(sample * levels) / levels;
        }
    </script>
</body>
</html>
