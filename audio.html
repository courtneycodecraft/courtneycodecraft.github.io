<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Digital Audio Encoding Demo</title>
    <style>
        canvas { border: 1px solid black; width: 100%; height: 200px; }
        #record { background-color: red; color: white; }
    </style>
</head>
<body>
    <h1>Digital Audio Encoding Demo</h1>
    <canvas id="waveform"></canvas>
    <canvas id="digitalWaveform"></canvas>
    <br>
    <label>Sampling Rate: <input type="range" id="sampleRate" min="8000" max="44100" step="1000" value="44100"></label>
    <br>
    <label>Bit Depth: <input type="range" id="bitDepth" min="2" max="16" step="1" value="16"></label>
    <br>
    <p id="fileSize">File Size: 0 KB</p>
    <button id="record">Record</button>
    <button id="play">Play</button>
    <p>Binary Representation of Samples:</p>
    <pre id="binaryOutput"></pre>
    <script>
        const canvas = document.getElementById("waveform");
        const digitalCanvas = document.getElementById("digitalWaveform");
        const ctx = canvas.getContext("2d");
        const digitalCtx = digitalCanvas.getContext("2d");
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const sampleRateSlider = document.getElementById("sampleRate");
        const bitDepthSlider = document.getElementById("bitDepth");
        const recordButton = document.getElementById("record");
        const playButton = document.getElementById("play");
        const fileSizeDisplay = document.getElementById("fileSize");
        const binaryOutput = document.getElementById("binaryOutput");
        let audioBuffer;
        let recorder;
        let audioChunks = [];
        let audioStream;
        let analyser;
        let sourceNode;
        
        navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
            audioStream = stream;
            recorder = new MediaRecorder(stream);
            const input = audioContext.createMediaStreamSource(stream);
            analyser = audioContext.createAnalyser();
            input.connect(analyser);
            
            recorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            recorder.onstart = () => {
                recordButton.style.backgroundColor = "green";
                recordButton.textContent = "Recording...";
            };
            recorder.onstop = async () => {
                recordButton.style.backgroundColor = "red";
                recordButton.textContent = "Record";
                const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
                const arrayBuffer = await audioBlob.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                drawWaveform(audioBuffer, ctx);
                updateFileSize(audioBuffer);
            };
        }).catch(error => {
            console.error("Error accessing microphone:", error);
            alert("Microphone access is required for recording.");
        });

        recordButton.onclick = () => {
            if (recorder && recorder.state === "inactive") {
                audioChunks = [];
                recorder.start();
                visualizeAudio();
                setTimeout(() => recorder.stop(), 3000); // Record for 3 seconds
            }
        };

        playButton.onclick = () => {
            if (!audioBuffer) return;
            const source = audioContext.createBufferSource();
            const encodedBuffer = encodeAudio(audioBuffer, sampleRateSlider.value, bitDepthSlider.value);
            source.buffer = encodedBuffer;
            source.connect(audioContext.destination);
            source.start();
            drawWaveform(encodedBuffer, digitalCtx);
            displayBinarySamples(encodedBuffer);
        };

        function visualizeAudio() {
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            function draw() {
                requestAnimationFrame(draw);
                analyser.getByteTimeDomainData(dataArray);
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.beginPath();
                for (let i = 0; i < dataArray.length; i++) {
                    const x = (i / dataArray.length) * canvas.width;
                    const y = (1 - (dataArray[i] / 255)) * canvas.height;
                    if (i === 0) ctx.moveTo(x, y);
                    else ctx.lineTo(x, y);
                }
                ctx.stroke();
            }
            draw();
        }

        function displayBinarySamples(buffer) {
            const data = buffer.getChannelData(0);
            const bitDepth = bitDepthSlider.value;
            let binaryData = data.slice(0, 10).map(sample => {
                let quantized = quantizeSample(sample, bitDepth);
                return quantized.toFixed(3) + " -> " + (Math.round(quantized * ((1 << bitDepth) - 1))).toString(2).padStart(bitDepth, '0');
            }).join('\n');
            binaryOutput.textContent = binaryData;
        }

        function quantizeSample(sample, bitDepth) {
            const levels = Math.pow(2, bitDepth) - 1;
            return Math.round(sample * levels) / levels;
        }
    </script>
</body>
</html>
