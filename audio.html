<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Digital Audio Encoding Demo</title>
    <style>
        canvas { border: 1px solid black; width: 100%; height: 200px; }
    </style>
</head>
<body>
    <h1>Digital Audio Encoding Demo</h1>
    <canvas id="waveform"></canvas>
    <br>
    <label>Sampling Rate: <input type="range" id="sampleRate" min="8000" max="44100" step="1000" value="44100"></label>
    <br>
    <label>Bit Depth: <input type="range" id="bitDepth" min="2" max="16" step="1" value="16"></label>
    <br>
    <button id="record">Record</button>
    <button id="play">Play</button>
    <script>
        const canvas = document.getElementById("waveform");
        const ctx = canvas.getContext("2d");
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const sampleRateSlider = document.getElementById("sampleRate");
        const bitDepthSlider = document.getElementById("bitDepth");
        const recordButton = document.getElementById("record");
        const playButton = document.getElementById("play");
        let audioBuffer;
        let recorder;
        let audioChunks = [];

        navigator.mediaDevices.getUserMedia({ audio: true }).then((stream) => {
            recorder = new MediaRecorder(stream);
            recorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            recorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: "audio/wav" });
                const arrayBuffer = await audioBlob.arrayBuffer();
                audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                drawWaveform(audioBuffer);
            };
        });

        recordButton.onclick = () => {
            audioChunks = [];
            recorder.start();
            setTimeout(() => recorder.stop(), 3000); // Record for 3 seconds
        };

        playButton.onclick = () => {
            if (!audioBuffer) return;
            const source = audioContext.createBufferSource();
            source.buffer = encodeAudio(audioBuffer, sampleRateSlider.value, bitDepthSlider.value);
            source.connect(audioContext.destination);
            source.start();
        };

        function encodeAudio(buffer, sampleRate, bitDepth) {
            const numChannels = buffer.numberOfChannels;
            const length = Math.floor(buffer.length * (sampleRate / buffer.sampleRate));
            const newBuffer = audioContext.createBuffer(numChannels, length, sampleRate);
            for (let channel = 0; channel < numChannels; channel++) {
                const oldData = buffer.getChannelData(channel);
                const newData = newBuffer.getChannelData(channel);
                for (let i = 0; i < length; i++) {
                    let sample = oldData[Math.floor(i * (buffer.sampleRate / sampleRate))] || 0;
                    newData[i] = quantizeSample(sample, bitDepth);
                }
            }
            return newBuffer;
        }

        function quantizeSample(sample, bitDepth) {
            const levels = Math.pow(2, bitDepth) - 1;
            return Math.round(sample * levels) / levels;
        }

        function drawWaveform(buffer) {
            ctx.clearRect(0, 0, canvas.width, canvas.height);
            const data = buffer.getChannelData(0);
            ctx.beginPath();
            for (let i = 0; i < data.length; i += 100) {
                const x = (i / data.length) * canvas.width;
                const y = (1 - (data[i] + 1) / 2) * canvas.height;
                if (i === 0) ctx.moveTo(x, y);
                else ctx.lineTo(x, y);
            }
            ctx.stroke();
        }
    </script>
</body>
</html>
